{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117f260f",
   "metadata": {
    "id": "-YlRH3mQM9tf",
    "papermill": {
     "duration": 0.023359,
     "end_time": "2022-12-15T14:47:27.491128",
     "exception": false,
     "start_time": "2022-12-15T14:47:27.467769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1daa9eb",
   "metadata": {
    "id": "MIEGXF8oM9tt",
    "papermill": {
     "duration": 1.44716,
     "end_time": "2022-12-15T14:47:28.943352",
     "exception": false,
     "start_time": "2022-12-15T14:47:27.496192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef85f02d",
   "metadata": {
    "id": "8UKlPFcBNZl5",
    "outputId": "c4eb79b7-0097-427e-f25c-a5f5e9473449",
    "papermill": {
     "duration": 4.66841,
     "end_time": "2022-12-15T14:47:33.617326",
     "exception": false,
     "start_time": "2022-12-15T14:47:28.948916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !wget https://www.manythings.org/anki/rus-eng.zip\n",
    "# !unzip rus-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d63719",
   "metadata": {
    "id": "kyNnJyruM9t1",
    "papermill": {
     "duration": 0.016304,
     "end_time": "2022-12-15T14:47:33.639548",
     "exception": false,
     "start_time": "2022-12-15T14:47:33.623244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9c0f63",
   "metadata": {
    "id": "FXKs8j4bM9t6",
    "papermill": {
     "duration": 0.013851,
     "end_time": "2022-12-15T14:47:33.658903",
     "exception": false,
     "start_time": "2022-12-15T14:47:33.645052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Zа-яёъА-ЯЁЪ.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00723d77-e330-469e-be75-f29b79141041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_opensubtitles_data(file_path_ru, file_path_en, num_samples=100_000):\n",
    "    input_texts = []\n",
    "    with open(file_path_en, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[:num_samples]:\n",
    "            en_text = line.strip()\n",
    "            input_texts.append(normalizeString(en_text))\n",
    "    target_texts = []\n",
    "    with open(file_path_ru, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[:num_samples]:\n",
    "            ru_text = line.strip()\n",
    "            target_texts.append(normalizeString(ru_text))\n",
    "    return input_texts, target_texts\n",
    "\n",
    "def load_anki_data(file_path, num_samples=100_000):\n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[:num_samples]:\n",
    "            en_text, ru_text = line.strip().split('\\t')[:-1]\n",
    "            input_texts.append(normalizeString(en_text))\n",
    "            target_texts.append(normalizeString(ru_text)) \n",
    "    return input_texts, target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e09b22ee",
   "metadata": {
    "id": "D8T4VxZeM9t-",
    "papermill": {
     "duration": 0.015274,
     "end_time": "2022-12-15T14:47:33.679754",
     "exception": false,
     "start_time": "2022-12-15T14:47:33.664480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # lines = open('anki_data/rus.txt', encoding='utf-8').\\\n",
    "    #     read().strip().split('\\n')\n",
    "\n",
    "    # pairs = [[normalizeString(s) for s in l.split('\\t')][0:2] for l in lines]\n",
    "    anki_input_texts, anki_target_texts = load_anki_data('anki_data/rus.txt')\n",
    "    opensub_input_texts, opensub_target_texts = load_opensubtitles_data('opensubtitles_data/OpenSubtitles.en-ru.ru',\n",
    "                                                                 'opensubtitles_data/OpenSubtitles.en-ru.en')\n",
    "    pairs = list(zip(anki_input_texts, anki_target_texts)) + list(zip(opensub_input_texts, opensub_target_texts))\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16bac210",
   "metadata": {
    "id": "eBOwgEBdM9uB",
    "papermill": {
     "duration": 0.014325,
     "end_time": "2022-12-15T14:47:33.699575",
     "exception": false,
     "start_time": "2022-12-15T14:47:33.685250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH  and \\\n",
    "        p[0].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46ed1b40",
   "metadata": {
    "id": "6dZOGjd5M9uE",
    "outputId": "0cdd3a7f-2ac8-4872-8a81-6101d0bdd0a9",
    "papermill": {
     "duration": 32.002035,
     "end_time": "2022-12-15T14:48:05.707125",
     "exception": false,
     "start_time": "2022-12-15T14:47:33.705090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 123924 sentence pairs\n",
      "Trimmed to 11743 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 2663\n",
      "rus 5399\n",
      "('i am right for once .', 'на этот раз я прав .')\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'rus', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960bd097",
   "metadata": {
    "id": "vgtWqznCM9uH",
    "papermill": {
     "duration": 0.005842,
     "end_time": "2022-12-15T14:48:05.719104",
     "exception": false,
     "start_time": "2022-12-15T14:48:05.713262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The Encoder\n",
    "-----------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d762e71a",
   "metadata": {
    "id": "m9vm9QBWM9uI",
    "papermill": {
     "duration": 0.018047,
     "end_time": "2022-12-15T14:48:05.742909",
     "exception": false,
     "start_time": "2022-12-15T14:48:05.724862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,num_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.num_layers=num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size,num_layers)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        if str(self.rnn)[:4] == 'LSTM':\n",
    "            return (torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n",
    "                ,torch.zeros(self.num_layers, 1, self.hidden_size, device=device))\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a47cc45",
   "metadata": {
    "id": "FwLTlgSyM9uK",
    "papermill": {
     "duration": 0.005445,
     "end_time": "2022-12-15T14:48:05.753928",
     "exception": false,
     "start_time": "2022-12-15T14:48:05.748483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The Decoder\n",
    "-----------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d35ee7d",
   "metadata": {
    "id": "PFbuUL1LM9uL",
    "papermill": {
     "duration": 0.017102,
     "end_time": "2022-12-15T14:48:05.776590",
     "exception": false,
     "start_time": "2022-12-15T14:48:05.759488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size,num_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.num_layers=num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size,num_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        if str(self.rnn)[:4] == 'LSTM':\n",
    "            return (torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n",
    "                ,torch.zeros(self.num_layers, 1, self.hidden_size, device=device))\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86ed91d7",
   "metadata": {
    "id": "z6gGPtXFM9uQ",
    "papermill": {
     "duration": 0.015256,
     "end_time": "2022-12-15T14:48:05.797396",
     "exception": false,
     "start_time": "2022-12-15T14:48:05.782140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7fba88e",
   "metadata": {
    "id": "8Fn8VDv8M9uS",
    "papermill": {
     "duration": 0.018521,
     "end_time": "2022-12-15T14:48:05.821386",
     "exception": false,
     "start_time": "2022-12-15T14:48:05.802865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e630e2d9",
   "metadata": {
    "id": "EKsdwPmSM9uU",
    "papermill": {
     "duration": 0.013844,
     "end_time": "2022-12-15T14:48:05.840937",
     "exception": false,
     "start_time": "2022-12-15T14:48:05.827093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f32c1ce",
   "metadata": {
    "id": "C_z_k5IiM9uX",
    "papermill": {
     "duration": 0.017554,
     "end_time": "2022-12-15T14:48:05.863993",
     "exception": false,
     "start_time": "2022-12-15T14:48:05.846439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, \n",
    "               learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    print_time = time.time()\n",
    "    print_iter = 0\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        print_iter += 1\n",
    "    \n",
    "        if iter % 100 == 0 : \n",
    "            if (time.time() - print_time > 30) or iter == n_iters:\n",
    "                print_time = time.time()\n",
    "                print_loss_avg = print_loss_total / print_iter\n",
    "                print_iter = 0\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e17a54-b464-4872-ba8e-76fa527a2de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8813edb",
   "metadata": {
    "id": "0JXG-RzCM9uZ",
    "papermill": {
     "duration": 0.014332,
     "end_time": "2022-12-15T14:48:05.883718",
     "exception": false,
     "start_time": "2022-12-15T14:48:05.869386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ce66d81",
   "metadata": {
    "id": "3Bxf45h6M9ud",
    "papermill": {
     "duration": 0.016408,
     "end_time": "2022-12-15T14:48:05.905634",
     "exception": false,
     "start_time": "2022-12-15T14:48:05.889226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "503b09f1",
   "metadata": {
    "id": "1qUmQIGwM9uf",
    "papermill": {
     "duration": 0.013532,
     "end_time": "2022-12-15T14:48:05.924790",
     "exception": false,
     "start_time": "2022-12-15T14:48:05.911258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "462939a3",
   "metadata": {
    "id": "s_56t10oM9uh",
    "outputId": "f456b0b8-fc35-4199-fb19-b45c2330bf72",
    "papermill": {
     "duration": 967.220488,
     "end_time": "2022-12-15T15:04:13.150742",
     "exception": false,
     "start_time": "2022-12-15T14:48:05.930254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 30s (- 2m 28s) (1700 17%) 3.9214\n",
      "1m 0s (- 2m 3s) (3300 33%) 3.4849\n",
      "1m 31s (- 1m 31s) (5000 50%) 3.2697\n",
      "2m 1s (- 1m 2s) (6600 66%) 3.1544\n",
      "2m 32s (- 0m 35s) (8100 81%) 3.0345\n",
      "3m 3s (- 0m 5s) (9700 97%) 2.9514\n",
      "3m 9s (- 0m 0s) (10000 100%) 2.9736\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size,1).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words,1).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 10_000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd950c2a",
   "metadata": {
    "id": "xEoEylSyM9uj",
    "papermill": {
     "duration": 0.085424,
     "end_time": "2022-12-15T15:04:13.250006",
     "exception": false,
     "start_time": "2022-12-15T15:04:13.164582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> you re so dirty .\n",
      "= вы такие грязные !\n",
      "< ты все . . <EOS>\n",
      "\n",
      "> i m going to need some more money .\n",
      "= мне понадобится еще немного денег .\n",
      "< я все с в . . . <EOS>\n",
      "\n",
      "> i m satisfied with my salary .\n",
      "= я довольна своеи зарплатои .\n",
      "< я все с с томом . <EOS>\n",
      "\n",
      "> i m very busy these days .\n",
      "= я очень занят в эти дни !\n",
      "< я не очень . . . <EOS>\n",
      "\n",
      "> you re bugging me .\n",
      "= ты меня раздражаешь .\n",
      "< ты меня . . <EOS>\n",
      "\n",
      "> we re against that .\n",
      "= мы против этого .\n",
      "< мы все . . <EOS>\n",
      "\n",
      "> they are exhausted .\n",
      "= они обессилены .\n",
      "< они все . . <EOS>\n",
      "\n",
      "> i m sure tom is bored .\n",
      "= я уверен что тому скучно .\n",
      "< я уверен что том том . . <EOS>\n",
      "\n",
      "> we are teachers .\n",
      "= мы учителя .\n",
      "< мы все . <EOS>\n",
      "\n",
      "> i m not married anymore .\n",
      "= я больше не женат .\n",
      "< я не не . . . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044e724",
   "metadata": {
    "papermill": {
     "duration": 0.013024,
     "end_time": "2022-12-15T15:04:13.276096",
     "exception": false,
     "start_time": "2022-12-15T15:04:13.263072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Я попробовал разные RNN с разным количеством слоев\n",
    "Однослойная GRU быстрее обучается.\n",
    "Увеличение количесва слоев, в данном случае, снижает скорость обучения\n",
    "и не дает заметных плюсов.\n",
    "Качество перевода немного увеличивается по мере обучения, \n",
    "но нормального перевода данная модель не сделает, сколько не учи.\n",
    "Не ясно, что с переобучением\n",
    "Не представляю, как програмно оценить адекватность перевода"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1015.675364,
   "end_time": "2022-12-15T15:04:15.596131",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-15T14:47:19.920767",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
