{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fc42317-789f-49ab-bb9a-cbba886f63e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n",
      "--2024-09-12 08:10:21--  http://www.manythings.org/anki/rus-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... failed: nodename nor servname provided, or not known.\n",
      "wget: unable to resolve host address ‘www.manythings.org’\n",
      "--2024-09-12 08:10:21--  https://object.pouta.csc.fi/OPUS-OpenSubtitles/v1/moses/en-ru.txt.zip\n",
      "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... failed: nodename nor servname provided, or not known.\n",
      "wget: unable to resolve host address ‘object.pouta.csc.fi’\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!wget http://www.manythings.org/anki/rus-eng.zip -O 'data/rus-eng.zip'\n",
    "!wget https://object.pouta.csc.fi/OPUS-OpenSubtitles/v1/moses/en-ru.txt.zip -O 'data/en-ru.txt.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f6b6b3-37d8-45b1-9d92-8f93ab00e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d8d022-ec2e-4b11-90f1-116e52e5eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_anki_path = 'data/rus-eng.zip'\n",
    "# with zipfile.ZipFile(dataset_anki_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall('anki_data')\n",
    "# dataset_opensub_path = 'data/en-ru.txt.zip'\n",
    "# with zipfile.ZipFile(dataset_opensub_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall('opensubtitles_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd4e0a59-8613-4823-ba14-ed0948c661f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c8a667-62c8-4b85-8e52-9b43cc10f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) \\\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Zа-яёъА-ЯЁЪ.!?]+\", r\" \", s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31e51a44-8d77-489d-852a-6707cb2d6af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_opensubtitles_data(file_path_ru, file_path_en, num_samples=100_000):\n",
    "    input_texts = []\n",
    "    with open(file_path_en, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[:num_samples]:\n",
    "            en_text = line.strip()\n",
    "            input_texts.append(normalizeString(en_text))\n",
    "    target_texts = []\n",
    "    with open(file_path_ru, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[:num_samples]:\n",
    "            ru_text = line.strip()\n",
    "            target_texts.append(normalizeString(ru_text))\n",
    "    return input_texts, target_texts\n",
    "\n",
    "def load_anki_data(file_path, num_samples=100_000):\n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[:num_samples]:\n",
    "            en_text, ru_text = line.strip().split('\\t')[:-1]\n",
    "            input_texts.append(normalizeString(en_text))\n",
    "            target_texts.append(normalizeString(ru_text)) \n",
    "    return input_texts, target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05530c6-2939-4bd0-b576-68324ab33ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab5717-51b5-43f9-8a58-af5ac972517b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64d225a3-1621-455e-bed4-dea573fabcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # lines = open('anki_data/rus.txt', encoding='utf-8').\\\n",
    "    #     read().strip().split('\\n')\n",
    "\n",
    "    # pairs = [[normalizeString(s) for s in l.split('\\t')][0:2] for l in lines]\n",
    "    anki_input_texts, anki_target_texts = load_anki_data('anki_data/rus.txt')\n",
    "    opensub_input_texts, opensub_target_texts = load_opensubtitles_data('opensubtitles_data/OpenSubtitles.en-ru.ru',\n",
    "                                                                 'opensubtitles_data/OpenSubtitles.en-ru.en')\n",
    "    pairs = list(zip(anki_input_texts, anki_target_texts)) + list(zip(opensub_input_texts, opensub_target_texts))\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf7f677-98ec-4e04-8155-8aab93e75a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH  and \\\n",
    "        p[0].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af1bfcc1-2835-453d-9771-fa0480f84a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Counted words:\n",
      "eng 2663\n",
      "rus 5399\n",
      "('i m coming with you .', 'я поиду с тобои .')\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    pairs = filterPairs(pairs)\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'rus', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8781adf-7aa5-42aa-8ba0-3009736e92ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,num_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.num_layers=num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size,num_layers)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        if str(self.rnn)[:4] == 'LSTM':\n",
    "            return (torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n",
    "                ,torch.zeros(self.num_layers, 1, self.hidden_size, device=device))\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size,num_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.num_layers=num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size,num_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        if str(self.rnn)[:4] == 'LSTM':\n",
    "            return (torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n",
    "                ,torch.zeros(self.num_layers, 1, self.hidden_size, device=device))\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e8eeb6-791f-4fe9-a34f-bdb252ecc663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b945ff04-3606-4596-99e1-ec6fe66769c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    # Encode input tensor\n",
    "\n",
    "    loss = 0\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    # Decode using the encoded hidden state\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    if use_teacher_forcing:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]\n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            _, topi = decoder_output.topk(1)\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    return loss.item() / target_length\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c3801ee-35e5-40bc-b836-57fe62f3b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a3f507e-1b91-4b14-9731-6f24cb819a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000,\n",
    "               learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    print_time = time.time()\n",
    "    print_iter = 0\n",
    "    print_loss_total = 0\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    for iter_ in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter_ - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        print_iter += 1\n",
    "\n",
    "        if iter_ % 100 == 0 : \n",
    "            if (time.time() - print_time > 30) or iter_ == n_iters:\n",
    "                print_time = time.time()\n",
    "                print_loss_avg = print_loss_total / print_iter\n",
    "                print_iter = 0\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter_ / n_iters),\n",
    "                                             iter_, iter_ / n_iters * 100, print_loss_avg))\n",
    "        \n",
    "            \n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4575ca4d-c161-4a09-8f9d-82eaddac592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 31s (- 65m 6s) (800 0%) 4.1401\n",
      "1m 4s (- 62m 9s) (1700 1%) 3.6733\n",
      "1m 36s (- 59m 57s) (2600 2%) 3.6294\n",
      "2m 7s (- 58m 48s) (3500 3%) 3.4846\n",
      "2m 39s (- 57m 50s) (4400 4%) 3.3350\n",
      "3m 13s (- 57m 34s) (5300 5%) 3.2720\n",
      "3m 44s (- 58m 34s) (6000 6%) 3.2017\n",
      "4m 14s (- 58m 12s) (6800 6%) 3.1518\n",
      "4m 45s (- 57m 46s) (7600 7%) 3.0421\n",
      "5m 18s (- 57m 3s) (8500 8%) 2.9904\n",
      "5m 50s (- 56m 15s) (9400 9%) 3.0028\n",
      "6m 22s (- 55m 32s) (10300 10%) 2.9404\n",
      "6m 55s (- 54m 56s) (11200 11%) 2.8062\n",
      "7m 27s (- 54m 44s) (12000 12%) 2.8826\n",
      "8m 1s (- 55m 11s) (12700 12%) 2.7431\n",
      "8m 33s (- 55m 50s) (13300 13%) 2.7396\n",
      "9m 6s (- 56m 24s) (13900 13%) 2.6894\n",
      "9m 38s (- 56m 49s) (14500 14%) 2.7152\n",
      "10m 9s (- 57m 8s) (15100 15%) 2.7375\n",
      "10m 41s (- 57m 22s) (15700 15%) 2.6394\n",
      "11m 13s (- 57m 37s) (16300 16%) 2.6346\n",
      "11m 45s (- 57m 47s) (16900 16%) 2.6183\n",
      "12m 17s (- 57m 57s) (17500 17%) 2.5354\n",
      "12m 51s (- 58m 11s) (18100 18%) 2.6067\n",
      "13m 24s (- 58m 18s) (18700 18%) 2.4950\n",
      "13m 57s (- 58m 22s) (19300 19%) 2.4090\n",
      "14m 30s (- 58m 24s) (19900 19%) 2.4552\n",
      "15m 3s (- 58m 25s) (20500 20%) 2.5267\n",
      "15m 36s (- 58m 21s) (21100 21%) 2.3958\n",
      "16m 10s (- 58m 20s) (21700 21%) 2.4434\n",
      "16m 42s (- 58m 11s) (22300 22%) 2.3517\n",
      "17m 15s (- 58m 6s) (22900 22%) 2.3279\n",
      "17m 48s (- 57m 57s) (23500 23%) 2.2951\n",
      "18m 23s (- 57m 56s) (24100 24%) 2.2044\n",
      "18m 58s (- 57m 49s) (24700 24%) 2.1980\n",
      "19m 31s (- 57m 39s) (25300 25%) 2.2633\n",
      "20m 6s (- 57m 31s) (25900 25%) 2.2151\n",
      "20m 39s (- 57m 19s) (26500 26%) 2.2095\n",
      "21m 13s (- 57m 4s) (27100 27%) 2.1123\n",
      "21m 47s (- 56m 51s) (27700 27%) 2.1384\n",
      "22m 19s (- 56m 34s) (28300 28%) 2.1398\n",
      "22m 52s (- 56m 17s) (28900 28%) 2.2527\n",
      "23m 25s (- 55m 58s) (29500 29%) 2.0324\n",
      "23m 59s (- 55m 43s) (30100 30%) 2.0647\n",
      "24m 33s (- 55m 27s) (30700 30%) 2.0249\n",
      "25m 7s (- 55m 9s) (31300 31%) 2.0179\n",
      "25m 41s (- 54m 50s) (31900 31%) 2.0415\n",
      "26m 17s (- 54m 36s) (32500 32%) 2.0039\n",
      "26m 52s (- 54m 19s) (33100 33%) 1.9499\n",
      "27m 24s (- 54m 24s) (33500 33%) 1.7889\n",
      "27m 58s (- 54m 18s) (34000 34%) 1.9503\n",
      "28m 34s (- 54m 14s) (34500 34%) 1.9431\n",
      "29m 9s (- 54m 9s) (35000 35%) 1.8882\n",
      "29m 42s (- 54m 13s) (35400 35%) 1.9707\n",
      "30m 13s (- 54m 12s) (35800 35%) 1.8635\n",
      "62m 49s (- 112m 11s) (35900 35%) 1.8733\n",
      "78m 18s (- 139m 12s) (36000 36%) 1.9276\n",
      "93m 33s (- 165m 36s) (36100 36%) 1.9829\n",
      "110m 7s (- 194m 5s) (36200 36%) 2.0004\n",
      "128m 11s (- 224m 56s) (36300 36%) 1.7763\n",
      "143m 50s (- 251m 19s) (36400 36%) 1.6985\n",
      "176m 44s (- 307m 29s) (36500 36%) 1.9947\n",
      "193m 44s (- 335m 36s) (36600 36%) 1.8113\n",
      "209m 23s (- 361m 8s) (36700 36%) 1.6727\n",
      "225m 8s (- 386m 40s) (36800 36%) 1.9518\n",
      "241m 45s (- 413m 24s) (36900 36%) 1.8564\n",
      "259m 7s (- 441m 12s) (37000 37%) 1.6817\n",
      "268m 2s (- 454m 27s) (37100 37%) 1.7358\n",
      "268m 37s (- 445m 49s) (37600 37%) 1.8061\n",
      "269m 11s (- 435m 29s) (38200 38%) 1.7814\n",
      "269m 42s (- 425m 25s) (38800 38%) 1.8030\n",
      "270m 15s (- 415m 40s) (39400 39%) 1.8389\n",
      "270m 46s (- 406m 10s) (40000 40%) 1.6672\n",
      "271m 19s (- 396m 57s) (40600 40%) 1.7246\n",
      "271m 51s (- 388m 0s) (41200 41%) 1.7888\n",
      "272m 24s (- 379m 16s) (41800 41%) 1.7786\n",
      "272m 55s (- 370m 46s) (42400 42%) 1.6564\n",
      "273m 27s (- 362m 29s) (43000 43%) 1.6743\n",
      "273m 59s (- 354m 25s) (43600 43%) 1.6589\n",
      "274m 31s (- 346m 34s) (44200 44%) 1.6939\n",
      "275m 2s (- 338m 53s) (44800 44%) 1.5881\n",
      "275m 34s (- 331m 25s) (45400 45%) 1.5648\n",
      "276m 5s (- 324m 6s) (46000 46%) 1.7085\n",
      "276m 37s (- 317m 0s) (46600 46%) 1.6917\n",
      "277m 10s (- 310m 3s) (47200 47%) 1.5545\n",
      "277m 42s (- 303m 15s) (47800 47%) 1.6166\n",
      "278m 14s (- 296m 37s) (48400 48%) 1.5456\n",
      "278m 46s (- 290m 9s) (49000 49%) 1.4835\n",
      "279m 18s (- 283m 49s) (49600 49%) 1.4229\n",
      "279m 50s (- 277m 36s) (50200 50%) 1.4465\n",
      "280m 21s (- 271m 31s) (50800 50%) 1.5139\n",
      "280m 54s (- 265m 36s) (51400 51%) 1.5296\n",
      "281m 27s (- 259m 48s) (52000 52%) 1.5529\n",
      "281m 58s (- 254m 5s) (52600 52%) 1.4950\n",
      "282m 30s (- 248m 31s) (53200 53%) 1.4817\n",
      "283m 2s (- 243m 3s) (53800 53%) 1.4560\n",
      "283m 34s (- 237m 41s) (54400 54%) 1.3750\n",
      "284m 5s (- 232m 26s) (55000 55%) 1.4166\n",
      "284m 37s (- 227m 17s) (55600 55%) 1.3795\n",
      "285m 9s (- 222m 14s) (56200 56%) 1.4482\n",
      "285m 41s (- 217m 17s) (56800 56%) 1.3683\n",
      "286m 13s (- 212m 25s) (57400 57%) 1.3978\n",
      "286m 45s (- 207m 39s) (58000 57%) 1.3775\n",
      "287m 17s (- 202m 58s) (58600 58%) 1.3628\n",
      "287m 49s (- 198m 21s) (59200 59%) 1.3006\n",
      "288m 24s (- 193m 52s) (59800 59%) 1.3409\n",
      "288m 58s (- 189m 27s) (60400 60%) 1.4020\n",
      "289m 32s (- 185m 6s) (61000 61%) 1.3250\n",
      "290m 6s (- 180m 50s) (61600 61%) 1.3329\n",
      "290m 40s (- 176m 38s) (62200 62%) 1.2483\n",
      "291m 14s (- 172m 30s) (62800 62%) 1.2029\n",
      "291m 47s (- 168m 26s) (63400 63%) 1.2258\n",
      "292m 21s (- 164m 26s) (64000 64%) 1.2740\n",
      "292m 54s (- 160m 30s) (64600 64%) 1.2172\n",
      "293m 29s (- 156m 38s) (65200 65%) 1.1942\n",
      "294m 3s (- 152m 50s) (65800 65%) 1.2084\n",
      "294m 36s (- 149m 4s) (66400 66%) 1.1802\n",
      "295m 10s (- 145m 23s) (67000 67%) 1.1820\n",
      "295m 44s (- 141m 44s) (67600 67%) 1.1605\n",
      "296m 19s (- 138m 9s) (68200 68%) 1.2420\n",
      "296m 52s (- 134m 37s) (68800 68%) 1.2319\n",
      "297m 26s (- 131m 8s) (69400 69%) 1.1833\n",
      "298m 0s (- 127m 42s) (70000 70%) 1.1260\n",
      "298m 34s (- 124m 20s) (70600 70%) 1.2065\n",
      "299m 8s (- 121m 0s) (71200 71%) 1.1148\n",
      "299m 42s (- 117m 42s) (71800 71%) 1.1207\n",
      "300m 16s (- 114m 28s) (72400 72%) 1.1482\n",
      "300m 52s (- 111m 16s) (73000 73%) 1.1247\n",
      "301m 27s (- 108m 7s) (73600 73%) 1.0640\n",
      "302m 2s (- 105m 1s) (74200 74%) 1.1021\n",
      "302m 36s (- 101m 56s) (74800 74%) 1.0966\n",
      "303m 12s (- 98m 55s) (75400 75%) 1.1113\n",
      "303m 46s (- 95m 55s) (76000 76%) 1.0988\n",
      "304m 20s (- 92m 58s) (76600 76%) 0.9937\n",
      "304m 54s (- 90m 3s) (77200 77%) 1.0971\n",
      "305m 30s (- 87m 10s) (77800 77%) 1.0022\n",
      "306m 4s (- 84m 19s) (78400 78%) 0.9909\n",
      "306m 38s (- 81m 30s) (79000 79%) 1.0485\n",
      "307m 12s (- 78m 43s) (79600 79%) 1.0786\n",
      "307m 46s (- 75m 59s) (80200 80%) 1.0493\n",
      "308m 20s (- 73m 16s) (80800 80%) 1.0445\n",
      "308m 54s (- 70m 35s) (81400 81%) 0.9692\n",
      "309m 28s (- 67m 56s) (82000 82%) 0.9961\n",
      "310m 3s (- 64m 51s) (82700 82%) 0.9758\n",
      "310m 37s (- 61m 49s) (83400 83%) 0.9623\n",
      "311m 11s (- 58m 50s) (84100 84%) 0.9896\n",
      "311m 45s (- 55m 52s) (84800 84%) 0.9850\n",
      "312m 20s (- 52m 58s) (85500 85%) 0.9406\n",
      "312m 54s (- 50m 30s) (86100 86%) 1.0048\n",
      "313m 28s (- 48m 5s) (86700 86%) 0.9540\n",
      "314m 3s (- 45m 41s) (87300 87%) 0.9483\n",
      "314m 37s (- 43m 18s) (87900 87%) 0.9465\n",
      "315m 12s (- 40m 57s) (88500 88%) 0.9478\n",
      "315m 45s (- 38m 37s) (89100 89%) 0.9363\n",
      "316m 19s (- 36m 19s) (89700 89%) 0.8977\n",
      "316m 53s (- 34m 2s) (90300 90%) 0.8776\n",
      "317m 26s (- 31m 46s) (90900 90%) 0.8143\n",
      "317m 59s (- 29m 32s) (91500 91%) 0.9246\n",
      "319m 12s (- 28m 8s) (91900 91%) 0.8875\n",
      "319m 47s (- 26m 18s) (92400 92%) 0.9345\n",
      "320m 18s (- 24m 6s) (93000 93%) 0.8733\n",
      "320m 52s (- 21m 56s) (93600 93%) 0.8325\n",
      "321m 25s (- 19m 47s) (94200 94%) 0.9080\n",
      "321m 57s (- 17m 39s) (94800 94%) 0.9429\n",
      "322m 29s (- 15m 33s) (95400 95%) 0.8373\n",
      "323m 2s (- 13m 27s) (96000 96%) 0.8135\n",
      "323m 37s (- 11m 23s) (96600 96%) 0.8247\n",
      "324m 9s (- 9m 40s) (97100 97%) 0.8506\n",
      "324m 44s (- 7m 59s) (97600 97%) 0.8162\n",
      "325m 18s (- 6m 18s) (98100 98%) 0.8123\n",
      "325m 54s (- 4m 37s) (98600 98%) 0.8647\n",
      "326m 31s (- 2m 57s) (99100 99%) 0.8482\n",
      "327m 10s (- 1m 18s) (99600 99%) 0.9052\n",
      "327m 44s (- 0m 0s) (100000 100%) 0.7951\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size,1).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words,1).to(device)\n",
    "trainIters(encoder1, decoder1, 100_000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea5ffcb8-fffa-44e8-ba1e-571b85baa318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  \n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            _, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        return decoded_words\n",
    "            \n",
    "def evaluateRandomly(encoder, decoder, l, n=3):\n",
    "    pairs_ = [pair for pair in pairs if len(pair[0].split()) == l]\n",
    "    for i in range(n):\n",
    "        \n",
    "        \n",
    "        pair = random.choice(pairs_)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words= evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words[1:-1])\n",
    "        print('<', output_sentence)\n",
    "        print('')            \n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbff403a-d6ed-4813-915c-0fe975f196d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> you re very kind .\n",
      "= вы очень добры .\n",
      "< очень добры .\n",
      "\n",
      "> they re watching you .\n",
      "= они за тобои наблюдают .\n",
      "< за вами вами .\n",
      "\n",
      "> i am a translator .\n",
      "= я переводчик .\n",
      "< переводчица .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3 words\n",
    "evaluateRandomly(encoder1, decoder1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47dcdd72-eb0e-49a6-ace4-f6244a82cdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> i m sure i can help .\n",
      "= я уверен что могу помочь .\n",
      "< уверен что помочь помочь .\n",
      "\n",
      "> i m sorry i shot you .\n",
      "= прости что я в тебя выстрелил .\n",
      "< что я в вас .\n",
      "\n",
      "> i m sorry i told you .\n",
      "= простите что я вам это сказала .\n",
      "< что что это сказал .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6 words\n",
    "evaluateRandomly(encoder1, decoder1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c66f018a-6e4f-4232-9729-00e50417fb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> i m supposed to be gathering information .\n",
      "= я должен собирать информацию .\n",
      "< должен собирать информацию .\n",
      "\n",
      "> you re reading too much into it .\n",
      "= ты раздуваешь всякие мелочи .\n",
      "< раздуваешь это .\n",
      "\n",
      "> you re wearing a wedding ring carl !\n",
      "= карл ты лгал !\n",
      "< у ! !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7 words\n",
    "evaluateRandomly(encoder1, decoder1,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96bf0081-6066-4d73-9b7a-a0ca54f9fc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Слово 1 Слово 2  Косинусное расстояние       Тип\n",
      "0  толстыи  жирныи              -0.060063  Синонимы\n",
      "1  толстыи   худои               0.063148  Антонимы\n"
     ]
    }
   ],
   "source": [
    "def get_word_vector(word, encoder, decoder, vocab, device='cpu'):\n",
    "    input_tensor = torch.tensor([[vocab[word]]], device=device)\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_output, encoder_hidden = encoder(input_tensor[0], encoder_hidden)\n",
    "    \n",
    "    return encoder_hidden[0].squeeze(0)\n",
    "\n",
    "def evaluate_word_pairs(encoder, decoder, vocab, synonym_pairs, antonym_pairs, device='cpu'):\n",
    "    results = []\n",
    "\n",
    "    def cosine_similarity_torch(vec1, vec2):\n",
    "        cos = F.cosine_similarity(vec1, vec2)\n",
    "        return cos.item()\n",
    "\n",
    "    for word1, word2 in synonym_pairs:\n",
    "        vec1 = get_word_vector(word1, encoder, decoder, vocab, device)\n",
    "        vec2 = get_word_vector(word2, encoder, decoder, vocab, device)\n",
    "        cosine_sim = cosine_similarity_torch(vec1, vec2)\n",
    "        results.append([word1, word2, cosine_sim, \"Синонимы\"])\n",
    "\n",
    "    for word1, word2 in antonym_pairs:\n",
    "        vec1 = get_word_vector(word1, encoder, decoder, vocab, device)\n",
    "        vec2 = get_word_vector(word2, encoder, decoder, vocab, device)\n",
    "        cosine_sim = cosine_similarity_torch(vec1, vec2)\n",
    "        results.append([word1, word2, cosine_sim, \"Антонимы\"])\n",
    "\n",
    "    df = pd.DataFrame(results, columns=[\"Слово 1\", \"Слово 2\", \"Косинусное расстояние\", \"Тип\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "synonym_pairs = [(\"толстыи\", \"жирныи\")]\n",
    "antonym_pairs = [(\"толстыи\", \"худои\")]\n",
    "\n",
    "df_results = evaluate_word_pairs(encoder1, decoder1, output_lang.word2index, synonym_pairs, antonym_pairs)\n",
    "\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b9fd086-ff42-4a5b-a6ce-19412409b2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12e458-f391-43db-bcd7-1a2131b02de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
