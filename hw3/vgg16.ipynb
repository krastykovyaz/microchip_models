{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61307306-1246-48f1-8f3a-61bf04eacd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  218M  100  218M    0     0  25.0M      0  0:00:08  0:00:08 --:--:-- 28.3M\n",
      "tar: Option -L is not permitted in mode -x\n"
     ]
    }
   ],
   "source": [
    "# Скачивание датасета\n",
    "!curl https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz --output data/flowers.tgz\n",
    "!tar -xvzf data/flowers.tgz -C data/ -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d6e7bf-3786-4924-8201-621b05e271ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_dir = 'data/flower_photos'\n",
    "model_path = 'best_vgg16_flowers.pth'\n",
    "num_epochs = 10\n",
    "num_classes = 5\n",
    "learning_rate=0.001\n",
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f08ca0f-3b8e-4329-baab-302f660e3a74",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eef5c7f-bd02-4563-b158-04ee802a2c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksandr/Desktop/micro_llm/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/aleksandr/Desktop/micro_llm/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.6318 Acc: 0.7606\n",
      "val Loss: 0.4382 Acc: 0.8406\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.4611 Acc: 0.8297\n",
      "val Loss: 0.4226 Acc: 0.8515\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.4093 Acc: 0.8495\n",
      "val Loss: 0.4342 Acc: 0.8392\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.4084 Acc: 0.8501\n",
      "val Loss: 0.4269 Acc: 0.8542\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.3859 Acc: 0.8597\n",
      "val Loss: 0.4100 Acc: 0.8624\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3709 Acc: 0.8699\n",
      "val Loss: 0.4009 Acc: 0.8638\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3569 Acc: 0.8726\n",
      "val Loss: 0.3984 Acc: 0.8638\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3687 Acc: 0.8600\n",
      "val Loss: 0.3931 Acc: 0.8733\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.3569 Acc: 0.8678\n",
      "val Loss: 0.3918 Acc: 0.8624\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.3850 Acc: 0.8566\n",
      "val Loss: 0.3962 Acc: 0.8747\n"
     ]
    }
   ],
   "source": [
    "# Преобразования данных (например, изменение размера и нормализация)\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "train_split = 0.8\n",
    "image_datasets = datasets.ImageFolder(data_dir, transform=data_transforms['train'])\n",
    "train_size = int(train_split * len(image_datasets))\n",
    "val_size = len(image_datasets) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(image_datasets, [train_size, val_size])\n",
    "\n",
    "# Создаем DataLoader'ы для обучения и валидации\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=32, shuffle=True),\n",
    "    'val': DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "num_classes = len(image_datasets.classes)\n",
    "\n",
    "# Загрузка предобученной модели VGG-16\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Заморозим все слои, кроме последнего\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Изменим последний классификатор под количество классов в нашем датасете\n",
    "model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Определяем функцию потерь и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier[6].parameters(), lr=learning_rate)\n",
    "\n",
    "# Функция для обучения модели\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "    \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Включаем режим обучения\n",
    "            else:\n",
    "                model.eval()   # Включаем режим оценки\n",
    "    \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "    \n",
    "            # Проходим по батчам данных\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "    \n",
    "                # Обнуляем градиенты\n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "                # Прямой проход\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "    \n",
    "                    # Обратное распространение и оптимизация только на обучении\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "    \n",
    "                # Статистика\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Обучаем модель\n",
    "model = train_model(model, criterion, optimizer, num_epochs=num_epochs)\n",
    "\n",
    "# Сохраняем модель в файл\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e53aad0-ee2b-4a30-9807-8b65601e73ed",
   "metadata": {},
   "source": [
    "### Inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fe71a9c-445c-47c7-8848-13594a5c3aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksandr/Desktop/micro_llm/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/var/folders/9b/cz5kycc54pq7926rs5ddp6t00000gp/T/ipykernel_70488/3127508217.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path)) # Загружаем обученные веса\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=False)  # Создаем модель VGG-16 без предобученных весов\n",
    "model.classifier[6] = nn.Linear(4096, num_classes)  # Меняем последний классификационный слой\n",
    "model.load_state_dict(torch.load(model_path)) # Загружаем обученные веса\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc73c8b-ee09-484c-bc1c-222437bbec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation dataset: 0.8706\n",
      "CPU times: user 11min 13s, sys: 1min 38s, total: 12min 52s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Функция для выполнения инференса\n",
    "def inference(model, inputs):\n",
    "    inputs = inputs.to(device)\n",
    "    with torch.no_grad():  # Отключаем градиенты для инференса\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    return preds.cpu().numpy()  # Возвращаем предсказания в формате numpy\n",
    "\n",
    "# Оценка на валидационном наборе данных\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for inputs, labels in dataloaders['val']:\n",
    "    # Получаем предсказания модели\n",
    "    preds = inference(model, inputs)\n",
    "\n",
    "    # Сравнение предсказанных классов с истинными\n",
    "    correct += np.sum(preds == labels.numpy())\n",
    "    total += labels.size(0)\n",
    "\n",
    "# Выводим точность модели\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on validation dataset: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8d189c-1fad-4d65-ba49-230066d64739",
   "metadata": {},
   "source": [
    "### Save model to ONXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41dcdde1-5990-4335-a233-12ca13f47edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9b/cz5kycc54pq7926rs5ddp6t00000gp/T/ipykernel_70488/2472523256.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path)) # Загружаем обученные веса\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель VGG-16 успешно экспортирована в vgg16_flowers.onnx\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=False)  # Создаем модель VGG-16 без предобученных весов\n",
    "model.classifier[6] = torch.nn.Linear(4096, num_classes)  # Меняем последний классификационный слой\n",
    "model.load_state_dict(torch.load(model_path)) # Загружаем обученные веса\n",
    "model = model.to(device)\n",
    "model.eval()  # Устанавливаем режим оценки\n",
    "\n",
    "# Создаем фиктивный входной тензор (batch size 1, 3 канала, 224x224 пикселей)\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# Путь для сохранения ONNX модели\n",
    "onnx_model_path = 'vgg16_flowers.onnx'\n",
    "\n",
    "# Экспортируем модель в формат ONNX\n",
    "torch.onnx.export(\n",
    "    model,                     # Модель для экспорта\n",
    "    dummy_input,               # Пример входного тензора\n",
    "    onnx_model_path,           # Имя выходного файла\n",
    "    export_params=True,        # Экспортируем обученные параметры\n",
    "    opset_version=11,          # Версия ONNX opset\n",
    "    do_constant_folding=True,  # Оптимизация неизменяемых частей\n",
    "    input_names=['input'],     # Имя входного тензора\n",
    "    output_names=['output'],   # Имя выходного тензора\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})  # Динамическое изменение размера батча\n",
    "\n",
    "print(f\"Модель VGG-16 успешно экспортирована в {onnx_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a00755-9a39-4554-abc7-7d6af468840e",
   "metadata": {},
   "source": [
    "### Inference model in ONXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982e1a22-d3ee-45a6-8b7e-f1d0a54fbf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "ort_session = ort.InferenceSession(onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd1953d-9aff-40a8-ae9c-e5d4ec4d5968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation dataset: 0.8610\n",
      "CPU times: user 14min 34s, sys: 1min, total: 15min 35s\n",
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Функция для инференса\n",
    "def onnx_inference(ort_session, inputs):\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: inputs}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    return ort_outs\n",
    "\n",
    "# Оценка на валидационном наборе данных\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for inputs, labels in dataloaders['val']:\n",
    "    inputs_numpy = inputs.numpy()\n",
    "    outputs = onnx_inference(ort_session, inputs_numpy)\n",
    "    preds = np.argmax(outputs[0], axis=1)\n",
    "    correct += np.sum(preds == labels.numpy())\n",
    "    total += labels.size(0)\n",
    "\n",
    "# Выводим точность модели\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on validation dataset: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865431b2-7d54-40d1-9676-b5231531f8b1",
   "metadata": {},
   "source": [
    "### Save model in tensorflow ONXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c09bdb5d-ddda-4913-a221-1169a7950b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksandr/Desktop/micro_llm/venv/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_53_x, mul_3_y in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg16_flowers_tf_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg16_flowers_tf_model/assets\n",
      "INFO:absl:Writing fingerprint to vgg16_flowers_tf_model/fingerprint.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель экспортирована в TensorFlow формат: vgg16_flowers_tf_model\n"
     ]
    }
   ],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "import onnx\n",
    "\n",
    "# Загружаем модель в формате ONNX\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "\n",
    "# Конвертируем ONNX модель в TensorFlow формат\n",
    "tf_rep = prepare(onnx_model)\n",
    "tf_model_path = 'vgg16_flowers_tf_model'\n",
    "tf_rep.export_graph(tf_model_path)\n",
    "print(f\"Модель экспортирована в TensorFlow формат: {tf_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34518277-da52-461d-ac31-207a3340f3dc",
   "metadata": {},
   "source": [
    "### Inference model in tensorflow ONXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e95f062c-69ac-4185-a9e5-34d385aa768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Загрузка модели TensorFlow\n",
    "model = tf.saved_model.load(tf_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d433bb-7504-47f9-b265-605f98b86aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation dataset: 0.8569\n",
      "CPU times: user 17min 53s, sys: 1min 49s, total: 19min 42s\n",
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Выполняем инференс\n",
    "def tensorflow_inference(model, inputs):\n",
    "    inputs_tf = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "    outputs = model.signatures['serving_default'](inputs_tf)['output']\n",
    "    return outputs\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for inputs, labels in dataloaders['val']:\n",
    "    inputs_numpy = inputs.numpy()\n",
    "    outputs = tensorflow_inference(model, inputs_numpy)\n",
    "    preds = np.argmax(outputs, axis=1)\n",
    "    correct += np.sum(preds == labels.numpy())\n",
    "    total += labels.size(0)\n",
    "\n",
    "# Выводим точность модели\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on validation dataset: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d97424-ca93-46ff-9929-d80eedb884d1",
   "metadata": {},
   "source": [
    "_Inference model:_ <br/>\n",
    "Точность (Accuracy): 0.8706 <br/>\n",
    "Время обработки: 12 минут 52 секунды (время CPU) и 3 минуты 13 секунд (время \"на стене\"). <br/>\n",
    "Модель показывает наилучшую точность по сравнению с другими вариантами и является наиболее эффективной по времени обработки на стене.\n",
    "\n",
    "_Inference model в ONNX:_<br/>\n",
    "Точность: 0.8610 <br/>\n",
    "Время обработки: 15 минут 35 секунд (время CPU) и 4 минуты 25 секунд (время \"на стене\"). <br/>\n",
    "ONNX-версия модели несколько снижает точность (на 0.0096), однако затрачивает больше времени на обработку, что может быть не столь эффективным.\n",
    "\n",
    "_Inference model в TensorFlow ONNX:_<br/>\n",
    "Точность: 0.8569 <br/>\n",
    "Время обработки: 19 минут 42 секунды (время CPU) и 3 минуты 55 секунд (время \"на стене\"). <br/>\n",
    "Эта версия показывает самую низкую точность (на 0.0137 меньше, чем оригинальная модель), при этом время CPU оказывается самым долгим. Время на стене чуть лучше, чем у ONNX-версии, но по всем показателям эта модель уступает.\n",
    "\n",
    "Оригинальная модель демонстрирует лучшую точность (0.8706) и быстрое время выполнения. <br/>\n",
    "Вариант на TensorFlow ONNX демонстрирует самую низкую точность и длительное время обработки. <br/>\n",
    "__Рекомендуется использовать оригинальную версию модели для повышения точности и скорости__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d8050-2962-42da-862c-9a15dee813a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d42fa-e0f2-4e23-98ec-3615e90c8209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a2f517-cd05-4c48-97e0-f372602be108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1ed0f-8e1e-44b8-87ca-f3c18a0c5d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
